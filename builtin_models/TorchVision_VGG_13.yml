name: TorchVision_VGG_13 # name of your model
framework:
    name: Onnxruntime # framework for the model
    version: 1.6.0 # framework version constraint
version: 1.0 # version information in semantic version format
container: # containers used to perform model prediction
    # multiple platforms can be specified
    amd64:
        cpu: raiproject/carml-onnxruntime:amd64-cpu
        gpu: raiproject/carml-onnxruntime:amd64-gpu
    ppc64le:
        cpu: raiproject/carml-onnxruntime:ppc64le-gpu
        gpu: raiproject/carml-onnxruntime:ppc64le-gpu
description: >
    This model is a replication of the model described in the VGG publication.
    All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]
references: # references to papers / websites / etc.. describing the model
    - https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py
    - https://pytorch.org/docs/stable/torchvision/index.html
    - https://arxiv.org/pdf/1409.1556.pdf
# license of the model
license: unrestricted
# inputs to the model
inputs:
    # first input type for the model
    - type: image
      # description of the first input
      description: the input image
      parameters: # type parameters
          element_type: float32
          input_layer: 0
          layout: CHW
          color_mode: RGB
          dimensions: [3, 224, 224]
          mean: [123.675, 116.280, 103.530] # [0.485, 0.456, 0.406] * 255
          scale: [58.395, 57.120, 57.375]   # [0.229, 0.224. 0.225] * 255
output:
    # the type of the output
    type: classification
    # a description of the output parameter
    description: the output label
    parameters:
        # type parameters
        element_type: float32
        probabilities_layer: 0
        probabilities_transform: softmax
        features_url: http://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset.txt
        features_checksum: 4d234b5833aca44928065a180db3016a
model: # specifies model graph and weights resources
    graph_path: https://s3.amazonaws.com/store.carml.org/models/onnxruntime/torchvision_vgg13.onnx
    is_archive:
        false # if set, then the base_url is a url to an archive
        # the graph_path and weights_path then denote the
        # file names of the graph and weights within the archive
    graph_checksum: f8dc46560866f5267c8b14ab93ae096e
attributes: # extra network attributes
    kind: CNN # the kind of neural network (CNN, RNN, ...)
    training_dataset: ImageNet # dataset used to for training
    manifest_author: Yen-Hsiang Chang
