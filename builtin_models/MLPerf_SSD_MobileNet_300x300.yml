name: MLPerf_SSD_MobileNet_300x300 # name of your model
framework:
    name: Onnxruntime # framework for the model
    version: 1.6.0 # framework version constraint
version: 1.0 # version information in semantic version format
description: >
  MLPerf_SSD_MobileNet_300x300.
references: # references to papers / websites / etc.. describing the model
  - https://github.com/mlperf/inference/tree/master/v0.5/classification_and_detection
  - https://github.com/mlcommons/inference/blob/master/vision/classification_and_detection/tools/convert-to-onnx.sh
license: Apache License, Version 2.0 # license of the model
# inputs to the model
inputs:
    # first input type for the model
    - type: image
      # description of the first input
      description: the input image
      parameters: # type parameters
          element_type: uint8
          input_layer: 0
          layout: HWC
          color_mode: RGB
          dimensions: [3, 300, 300]
output:
    # the type of the output
    type: boundingbox
    # a description of the output parameter
    description: the output bounding box # a description of the output parameter
    parameters:
        classes_layer: 3
        boxes_layer: 1
        probabilities_layer: 2
        xmin_index: 1
        ymin_index: 0
        xmax_index: 3
        ymax_index: 2
        features_url: https://s3.amazonaws.com/store.carml.org/synsets/coco/coco_labels_paper_background.txt
        features_checksum: 17249a4106513972e03c00728e7cd380
model: # specifies model graph and weights resources
    graph_path: https://s3.amazonaws.com/store.carml.org/models/onnxruntime/ssd_mobilenet_v1_coco_2018_01_28.onnx
    is_archive:
        false # if set, then the base_url is a url to an archive
        # the graph_path and weights_path then denote the
        # file names of the graph and weights within the archive
    graph_checksum: f78c11efb00ee6e698de5fc61724074f
preprocess: |
  import numpy as np
  import cv2
  def maybe_resize(img, dims):
    img = np.array(img, dtype=np.float32)
    if len(img.shape) < 3 or img.shape[2] != 3:
      # some images might be grayscale
      img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    if dims != None:
      im_height, im_width, _ = dims
      img = cv2.resize(img, (im_width, im_height), interpolation=cv2.INTER_LINEAR)
    return img
  def pre_process_coco_mobilenet(img, dims=None, need_transpose=False):
    img = maybe_resize(img, dims)
    img = np.asarray(img, dtype=np.uint8)
    # transpose if needed
    if need_transpose:
      img = img.transpose([2, 0, 1])
    return img
  def preprocess(ctx, data):
    img = cv2.imread(data)
    return pre_process_coco_mobilenet(img, [300, 300, 3], False)
postprocess: |
  def postprocess(ctx, data):
    n = len(data[0])
    probabilities = []
    classes = []
    boxes = []
    for i in range(n):
      probabilities.append([])
      classes.append([])
      boxes.append([])
      detection_boxes = data[1][i]
      detection_classes = data[3][i]
      scores = data[2][i]
      for detection in range(len(scores)):
        probabilities[-1].append(scores[detection])
        classes[-1].append(float(detection_classes[detection]))
        box = detection_boxes[detection]
        boxes[-1].append([box[0], box[1], box[2], box[3]])

    return probabilities, classes, boxes

attributes: # extra network attributes
    kind: CNN # the kind of neural network (CNN, RNN, ...)
    training_dataset: COCO 2017 # dataset used to for training
    manifest_author: Yen-Hsiang Chang
