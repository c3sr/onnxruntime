name: MLPerf_SSD_ResNet34_1200x1200 # name of your model
framework:
    name: Onnxruntime # framework for the model
    version: 1.6.0 # framework version constraint
version: 1.0 # version information in semantic version format
description: >
  MLPerf_SSD_ResNet34_1200x1200.
references: # references to papers / websites / etc.. describing the model
  - https://github.com/mlperf/inference/tree/master/v0.5/classification_and_detection
  - https://github.com/mlperf/inference/tree/master/others/cloud/single_stage_detector/tensorflow
license: Apache License, Version 2.0 # license of the model
# inputs to the model
inputs:
    # first input type for the model
    - type: image
      # description of the first input
      description: the input image
      parameters: # type parameters
          element_type: float32
          input_layer: 0
          layout: CHW
          color_mode: RGB
          dimensions: [3, 1200, 1200]
          mean: [123.675, 116.280, 103.530] # [0.485, 0.456, 0.406] * 255
          scale: [58.395, 57.120, 57.375]   # [0.229, 0.224. 0.225] * 255
output:
    # the type of the output
    type: boundingbox
    # a description of the output parameter
    description: the output bounding box # a description of the output parameter
    parameters:
        classes_layer: 1
        boxes_layer: 0
        probabilities_layer: 2
        xmin_index: 0
        ymin_index: 1
        xmax_index: 2
        ymax_index: 3
        features_url: https://s3.amazonaws.com/store.carml.org/synsets/coco/coco_labels_2014_2017_background.txt
        features_checksum: e7103a997c945e0f87c49a03c9c56a1b
model: # specifies model graph and weights resources
    graph_path: https://s3.amazonaws.com/store.carml.org/models/onnxruntime/resnet34-ssd1200.onnx
    is_archive:
        false # if set, then the base_url is a url to an archive
        # the graph_path and weights_path then denote the
        # file names of the graph and weights within the archive
    graph_checksum: b70fc6c72bc9349981f3b1258f31bc87
preprocess: |
  import numpy as np
  import cv2
  def maybe_resize(img, dims):
    img = np.array(img, dtype=np.float32)
    if len(img.shape) < 3 or img.shape[2] != 3:
      # some images might be grayscale
      img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    if dims != None:
      im_height, im_width, _ = dims
      img = cv2.resize(img, (im_width, im_height), interpolation=cv2.INTER_LINEAR)
    return img
  def pre_process_coco_resnet34(img, dims=None, need_transpose=False):
    img = maybe_resize(img, dims)
    mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    std = np.array([0.229, 0.224, 0.225], dtype=np.float32)

    img = img / 255. - mean
    img = img / std

    if need_transpose:
      img = img.transpose([2, 0, 1])

    return img
  def preprocess(ctx, data):
    img = cv2.imread(data)
    return pre_process_coco_resnet34(img, [1200, 1200, 3], True)
postprocess: |
  def postprocess(ctx, data):
    n = len(data[0])
    probabilities = []
    classes = []
    boxes = []
    for i in range(n):
      probabilities.append([])
      classes.append([])
      boxes.append([])
      detection_boxes = data[0][i]
      detection_classes = data[1][i]
      scores = data[2][i]
      for detection in range(len(scores)):
        if scores[detection] < 0.05:
          break
        probabilities[-1].append(scores[detection])
        classes[-1].append(float(detection_classes[detection]))
        box = detection_boxes[detection]
        boxes[-1].append([box[1], box[0], box[3], box[2]])

    return probabilities, classes, boxes
attributes: # extra network attributes
    kind: CNN # the kind of neural network (CNN, RNN, ...)
    training_dataset: COCO 2017 # dataset used to for training
    manifest_author: Yen-Hsiang Chang
